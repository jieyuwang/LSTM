{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID                Time      flow\n",
      "0        1 2021-07-30 12:00:00  0.000000\n",
      "1        1 2021-07-30 13:00:00  0.000000\n",
      "2        1 2021-07-30 14:00:00  0.000000\n",
      "3        1 2021-07-30 15:00:00  0.000000\n",
      "4        1 2021-07-30 16:00:00  0.000035\n",
      "...     ..                 ...       ...\n",
      "399042  72 2022-01-05 19:00:00  4.355480\n",
      "399043  72 2022-01-05 20:00:00  5.709647\n",
      "399044  72 2022-01-05 21:00:00  5.444348\n",
      "399045  72 2022-01-05 22:00:00  3.633421\n",
      "399046  72 2022-01-05 23:00:00  3.885509\n",
      "\n",
      "[399047 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "sub_rowdata = pd.read_csv(r'datasets/@liuf109#3ac05fd206366fe07ad4a1b0a2167d78/data_v1_train.csv')\n",
    "#print(sub_rowdata.head(3))#可成功读到数据\n",
    "#print(sub_rowdata['ID'].head(3))\n",
    "# sub_rowdata = pd.DataFrame(sub_rowdata)\n",
    "\n",
    "split_rowdata = sub_rowdata['time'].astype('str').str.split(':',expand = True)\n",
    "split_rowdata.columns = ['Time','notrequire1']\n",
    "\n",
    "sub_rowdata = pd.concat([sub_rowdata['ID'],sub_rowdata['flow'],sub_rowdata['time'],split_rowdata['Time']],axis = 1)\n",
    "sub_rowdata['Time'] = pd.to_datetime(sub_rowdata['Time'])\n",
    "sub_rowdata.set_index('Time')\n",
    "#print(sub_rowdata)\n",
    "sub_rowdata_group = pd.DataFrame(sub_rowdata['flow'].groupby([sub_rowdata['ID'],sub_rowdata['Time']]).max())\n",
    "sub_rowdata_group.reset_index(inplace = True)\n",
    "#print(sub_rowdata_group)\n",
    "\n",
    "list = []\n",
    "test_network_ids = sub_rowdata_group['ID'].unique().tolist()\n",
    "#for index,raw in sub_rowdata_group.iterrows():\n",
    "#    sub_rowdata_group['ID'][index] = test_network_ids.index(raw['ID'])\n",
    "#class_mapping = {'A':0, 'B':1}\n",
    "#data[class] = data[class].map(class_mapping)\n",
    "shunxu = []\n",
    "for i in range(1,73):\n",
    "    shunxu.append(i)\n",
    "dictshunxu = {test_network_ids[i]:shunxu[i] for i in range(len(test_network_ids))}\n",
    "#print(dictshunxu)\n",
    "sub_rowdata_group['ID'] = sub_rowdata_group['ID'].map(dictshunxu)\n",
    "#sub_rowdata_group['ID'] = test_network_ids.index(sub_rowdata_group['ID'])\n",
    "print(sub_rowdata_group)\n",
    "sub_rowdata_group.to_csv(r'datasets/@liuf109#3ac05fd206366fe07ad4a1b0a2167d78/0LSTM/rowdata4/data_v1_train.csv',index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Time  ID       flow\n",
      "2484 2021-11-11 00:00:00   1  14.940597\n",
      "2485 2021-11-11 01:00:00   1  11.228764\n",
      "2486 2021-11-11 02:00:00   1   7.789449\n",
      "2487 2021-11-11 03:00:00   1   5.606784\n",
      "2488 2021-11-11 04:00:00   1   4.346419\n",
      "                    Time  ID       flow  flow_cnt_hours\n",
      "2484 2021-11-11 00:00:00   1  14.940597       11.228764\n",
      "2485 2021-11-11 01:00:00   1  11.228764        7.789449\n",
      "2486 2021-11-11 02:00:00   1   7.789449        5.606784\n",
      "2487 2021-11-11 03:00:00   1   5.606784        4.346419\n",
      "2488 2021-11-11 04:00:00   1   4.346419        2.765237\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Time</th>\n",
       "      <th>ID</th>\n",
       "      <th>2021-11-11 00:00:00</th>\n",
       "      <th>2021-11-11 01:00:00</th>\n",
       "      <th>2021-11-11 02:00:00</th>\n",
       "      <th>2021-11-11 03:00:00</th>\n",
       "      <th>2021-11-11 04:00:00</th>\n",
       "      <th>2021-11-11 05:00:00</th>\n",
       "      <th>2021-11-11 06:00:00</th>\n",
       "      <th>2021-11-11 07:00:00</th>\n",
       "      <th>2021-11-11 08:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2022-01-04 15:00:00</th>\n",
       "      <th>2022-01-04 16:00:00</th>\n",
       "      <th>2022-01-04 17:00:00</th>\n",
       "      <th>2022-01-04 18:00:00</th>\n",
       "      <th>2022-01-04 19:00:00</th>\n",
       "      <th>2022-01-04 20:00:00</th>\n",
       "      <th>2022-01-04 21:00:00</th>\n",
       "      <th>2022-01-04 22:00:00</th>\n",
       "      <th>2022-01-04 23:00:00</th>\n",
       "      <th>2022-01-05 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.940597</td>\n",
       "      <td>11.228764</td>\n",
       "      <td>7.789449</td>\n",
       "      <td>5.606784</td>\n",
       "      <td>4.346419</td>\n",
       "      <td>2.765237</td>\n",
       "      <td>2.164130</td>\n",
       "      <td>1.909579</td>\n",
       "      <td>1.764144</td>\n",
       "      <td>...</td>\n",
       "      <td>32.276536</td>\n",
       "      <td>31.344990</td>\n",
       "      <td>38.202700</td>\n",
       "      <td>32.211554</td>\n",
       "      <td>32.570896</td>\n",
       "      <td>32.464790</td>\n",
       "      <td>33.916440</td>\n",
       "      <td>34.193040</td>\n",
       "      <td>41.806024</td>\n",
       "      <td>33.298078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>171.393376</td>\n",
       "      <td>194.398368</td>\n",
       "      <td>130.993616</td>\n",
       "      <td>99.554840</td>\n",
       "      <td>80.535488</td>\n",
       "      <td>92.845264</td>\n",
       "      <td>14.909455</td>\n",
       "      <td>11.569733</td>\n",
       "      <td>39.393544</td>\n",
       "      <td>...</td>\n",
       "      <td>72.541768</td>\n",
       "      <td>66.852568</td>\n",
       "      <td>49.098912</td>\n",
       "      <td>39.061472</td>\n",
       "      <td>20.710768</td>\n",
       "      <td>36.346252</td>\n",
       "      <td>22.144236</td>\n",
       "      <td>14.566312</td>\n",
       "      <td>13.964399</td>\n",
       "      <td>145.212896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.337608</td>\n",
       "      <td>0.898661</td>\n",
       "      <td>0.892589</td>\n",
       "      <td>0.950358</td>\n",
       "      <td>0.971776</td>\n",
       "      <td>1.031840</td>\n",
       "      <td>1.023965</td>\n",
       "      <td>3.603804</td>\n",
       "      <td>11.632146</td>\n",
       "      <td>...</td>\n",
       "      <td>16.385352</td>\n",
       "      <td>26.629262</td>\n",
       "      <td>21.052872</td>\n",
       "      <td>20.065878</td>\n",
       "      <td>19.814414</td>\n",
       "      <td>10.579760</td>\n",
       "      <td>2.125028</td>\n",
       "      <td>1.222016</td>\n",
       "      <td>0.831786</td>\n",
       "      <td>0.876630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13.628420</td>\n",
       "      <td>13.348012</td>\n",
       "      <td>12.889409</td>\n",
       "      <td>43.200124</td>\n",
       "      <td>20.730514</td>\n",
       "      <td>14.674860</td>\n",
       "      <td>15.516320</td>\n",
       "      <td>14.457233</td>\n",
       "      <td>51.089156</td>\n",
       "      <td>...</td>\n",
       "      <td>10.914105</td>\n",
       "      <td>34.225372</td>\n",
       "      <td>12.173839</td>\n",
       "      <td>11.977692</td>\n",
       "      <td>12.526954</td>\n",
       "      <td>17.508036</td>\n",
       "      <td>11.938904</td>\n",
       "      <td>12.032740</td>\n",
       "      <td>12.688840</td>\n",
       "      <td>10.493511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>98.822280</td>\n",
       "      <td>98.797248</td>\n",
       "      <td>100.314008</td>\n",
       "      <td>99.969200</td>\n",
       "      <td>100.047800</td>\n",
       "      <td>100.329056</td>\n",
       "      <td>101.291632</td>\n",
       "      <td>99.652504</td>\n",
       "      <td>100.145744</td>\n",
       "      <td>...</td>\n",
       "      <td>58.850700</td>\n",
       "      <td>58.355488</td>\n",
       "      <td>57.270252</td>\n",
       "      <td>52.769920</td>\n",
       "      <td>48.739160</td>\n",
       "      <td>46.607900</td>\n",
       "      <td>44.257068</td>\n",
       "      <td>40.258384</td>\n",
       "      <td>37.989864</td>\n",
       "      <td>34.217884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1322 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Time  ID  2021-11-11 00:00:00  2021-11-11 01:00:00  2021-11-11 02:00:00  \\\n",
       "0      1            14.940597            11.228764             7.789449   \n",
       "1      2           171.393376           194.398368           130.993616   \n",
       "2      3             1.337608             0.898661             0.892589   \n",
       "3      4            13.628420            13.348012            12.889409   \n",
       "4      5            98.822280            98.797248           100.314008   \n",
       "\n",
       "Time  2021-11-11 03:00:00  2021-11-11 04:00:00  2021-11-11 05:00:00  \\\n",
       "0                5.606784             4.346419             2.765237   \n",
       "1               99.554840            80.535488            92.845264   \n",
       "2                0.950358             0.971776             1.031840   \n",
       "3               43.200124            20.730514            14.674860   \n",
       "4               99.969200           100.047800           100.329056   \n",
       "\n",
       "Time  2021-11-11 06:00:00  2021-11-11 07:00:00  2021-11-11 08:00:00  ...  \\\n",
       "0                2.164130             1.909579             1.764144  ...   \n",
       "1               14.909455            11.569733            39.393544  ...   \n",
       "2                1.023965             3.603804            11.632146  ...   \n",
       "3               15.516320            14.457233            51.089156  ...   \n",
       "4              101.291632            99.652504           100.145744  ...   \n",
       "\n",
       "Time  2022-01-04 15:00:00  2022-01-04 16:00:00  2022-01-04 17:00:00  \\\n",
       "0               32.276536            31.344990            38.202700   \n",
       "1               72.541768            66.852568            49.098912   \n",
       "2               16.385352            26.629262            21.052872   \n",
       "3               10.914105            34.225372            12.173839   \n",
       "4               58.850700            58.355488            57.270252   \n",
       "\n",
       "Time  2022-01-04 18:00:00  2022-01-04 19:00:00  2022-01-04 20:00:00  \\\n",
       "0               32.211554            32.570896            32.464790   \n",
       "1               39.061472            20.710768            36.346252   \n",
       "2               20.065878            19.814414            10.579760   \n",
       "3               11.977692            12.526954            17.508036   \n",
       "4               52.769920            48.739160            46.607900   \n",
       "\n",
       "Time  2022-01-04 21:00:00  2022-01-04 22:00:00  2022-01-04 23:00:00  \\\n",
       "0               33.916440            34.193040            41.806024   \n",
       "1               22.144236            14.566312            13.964399   \n",
       "2                2.125028             1.222016             0.831786   \n",
       "3               11.938904            12.032740            12.688840   \n",
       "4               44.257068            40.258384            37.989864   \n",
       "\n",
       "Time  2022-01-05 00:00:00  \n",
       "0               33.298078  \n",
       "1              145.212896  \n",
       "2                0.876630  \n",
       "3               10.493511  \n",
       "4               34.217884  \n",
       "\n",
       "[5 rows x 1322 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hours = sub_rowdata_group[['Time','ID','flow']]\n",
    "#train_hours = train_hours.sort_values('Time').groupby(['ID'], as_index=False)\n",
    "#train_hours = train_hours.agg({'flow'})\n",
    "#train_hours.columns = ['Time', 'ID', 'flow']\n",
    "train_hours = train_hours.query('Time >= \"2021-11-11 00:00:00\" and Time <= \"2022-01-05 00:00:00\"')\n",
    "print(train_hours.head())\n",
    "train_hours['flow_cnt_hours'] = train_hours.sort_values('Time').groupby(['ID'])['flow'].shift(-1)\n",
    "print(train_hours.head())\n",
    "\n",
    "monthly_series = train_hours.pivot_table(index=['ID'], columns='Time',values='flow', fill_value=0).reset_index()\n",
    "monthly_series.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 1321)\n",
      "(72, 1)\n",
      "Train set reshaped (64, 1321, 1)\n",
      "Validation set reshaped (8, 1321, 1)\n"
     ]
    }
   ],
   "source": [
    "data_series = pd.DataFrame(monthly_series)\n",
    "test_network_ids = data_series['ID'].unique()\n",
    "#print(data_series.head())\n",
    "#print(data_series.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 最后N条数据作为测试数据\n",
    "testNum = 1\n",
    "# 将数据分割为训练集和测试集，此时分割的数据集是二维数组（取最后12条数据作为测试数据）\n",
    "train, test = data_series.iloc[:,:-testNum], monthly_series.iloc[:,-testNum:]\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "train, valid, Y_train, Y_valid = train_test_split(train, test.values, test_size=0.10, random_state=0)\n",
    "\n",
    "#print(train)\n",
    "#print(valid)\n",
    "X_train = train.values.reshape((train.shape[0], train.shape[1], 1))\n",
    "X_valid = valid.values.reshape((valid.shape[0], valid.shape[1], 1))\n",
    "\n",
    "print(\"Train set reshaped\", X_train.shape)\n",
    "print(\"Validation set reshaped\", X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/python3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1184: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`normal` is a deprecated alias for `truncated_normal`\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 1321, 10)          480       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1321, 6)           408       \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1)                 32        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,061\n",
      "Trainable params: 1,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 64 samples, validate on 8 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 33.8847 - mean_absolute_error: 33.8847 - val_loss: 56.3943 - val_mean_absolute_error: 56.3943\n",
      "Epoch 2/10\n",
      " - 2s - loss: 33.8831 - mean_absolute_error: 33.8831 - val_loss: 56.3924 - val_mean_absolute_error: 56.3924\n",
      "Epoch 3/10\n",
      " - 2s - loss: 33.8811 - mean_absolute_error: 33.8811 - val_loss: 56.3906 - val_mean_absolute_error: 56.3906\n",
      "Epoch 4/10\n",
      " - 2s - loss: 33.8794 - mean_absolute_error: 33.8794 - val_loss: 56.3888 - val_mean_absolute_error: 56.3888\n",
      "Epoch 5/10\n",
      " - 2s - loss: 33.8775 - mean_absolute_error: 33.8775 - val_loss: 56.3869 - val_mean_absolute_error: 56.3869\n",
      "Epoch 6/10\n",
      " - 2s - loss: 33.8756 - mean_absolute_error: 33.8756 - val_loss: 56.3849 - val_mean_absolute_error: 56.3849\n",
      "Epoch 7/10\n",
      " - 2s - loss: 33.8736 - mean_absolute_error: 33.8736 - val_loss: 56.3829 - val_mean_absolute_error: 56.3829\n",
      "Epoch 8/10\n",
      " - 2s - loss: 33.8717 - mean_absolute_error: 33.8717 - val_loss: 56.3809 - val_mean_absolute_error: 56.3809\n",
      "Epoch 9/10\n",
      " - 2s - loss: 33.8697 - mean_absolute_error: 33.8697 - val_loss: 56.3789 - val_mean_absolute_error: 56.3789\n",
      "Epoch 10/10\n",
      " - 2s - loss: 33.8677 - mean_absolute_error: 33.8677 - val_loss: 56.3768 - val_mean_absolute_error: 56.3768\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import optimizers, Sequential, Model\n",
    "import tensorflow.keras.layers as L\n",
    "\n",
    "serie_size =  X_train.shape[1] # 12\n",
    "n_features =  X_train.shape[2] # 1\n",
    "\n",
    "epochs = 10\n",
    "batch = 128\n",
    "lr = 0.0001\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(L.LSTM(10, input_shape=(serie_size, n_features), return_sequences=True))\n",
    "lstm_model.add(L.LSTM(6, activation='relu', return_sequences=True))\n",
    "lstm_model.add(L.LSTM(1, activation='relu'))\n",
    "lstm_model.add(L.Dense(10, kernel_initializer='glorot_normal', activation='relu'))\n",
    "lstm_model.add(L.Dense(10, kernel_initializer='glorot_normal', activation='relu'))\n",
    "lstm_model.add(L.Dense(1))\n",
    "lstm_model.summary()\n",
    "\n",
    "adam = optimizers.Adam(lr)\n",
    "lstm_model.compile(loss='mean_absolute_error', optimizer='adam',metrics = ['mae'])\n",
    "\n",
    "\n",
    "lstm_history = lstm_model.fit(X_train, Y_train,\n",
    "                              validation_data=(X_valid, Y_valid),\n",
    "                              batch_size=batch,\n",
    "                              epochs=epochs,\n",
    "                              verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1321, 1)\n",
      "(8, 1)\n",
      "Train mae: 33.865762603935536\n",
      "Validation mae: 56.376845669468395\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "print(X_valid.shape)\n",
    "lstm_train_pred = lstm_model.predict(X_train)\n",
    "lstm_val_pred = lstm_model.predict(X_valid)\n",
    "print(lstm_val_pred.shape)\n",
    "print('Train mae:', mean_absolute_error(Y_train, lstm_train_pred))\n",
    "print('Validation mae:', mean_absolute_error(Y_valid, lstm_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 72)                21312     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 24)                1752      \n",
      "=================================================================\n",
      "Total params: 23,064\n",
      "Trainable params: 23,064\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_11 to have shape (24,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2ab40e0dc0eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# creating submission file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1276\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps_per_epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m         validation_split=validation_split)\n\u001b[0m\u001b[1;32m   1279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    915\u001b[0m           \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m           exception_prefix='target')\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0;34m'Error when checking '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 ' but got array with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    192\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_11 to have shape (24,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense,Dropout\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras import optimizers, Sequential, Model\n",
    "\n",
    "# our defining our model \n",
    "my_model = Sequential()\n",
    "my_model.add(LSTM(units = 72,input_shape = (1321,1)))\n",
    "my_model.add(Dropout(0.4))\n",
    "my_model.add(Dense(1))\n",
    "\n",
    "my_model.compile(loss = 'mse',optimizer = 'adam', metrics = ['mean_absolute_error'])\n",
    "my_model.summary()\n",
    "my_model.fit(X_train,Y_train,batch_size = 4096,epochs = 20)\n",
    "\n",
    "# creating submission file \n",
    "lstm_train_pred = lstm_model.predict(X_train)\n",
    "submission_pfs = my_model.predict(X_valid)\n",
    "print('Train mae:', mean_absolute_error(Y_train, lstm_train_pred))\n",
    "print('Validation mae:', mean_absolute_error(Y_valid, lstm_val_pred))\n",
    "# we will keep every value between 0 and 20\n",
    "#submission_pfs = submission_pfs.clip(0,20)\n",
    "# creating dataframe with required columns \n",
    "#submission = pd.DataFrame({'ID':test_data['ID'],'item_cnt_month':submission_pfs.ravel()})\n",
    "# creating csv file from dataframe\n",
    "#submission.to_csv('sub_pfs.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_month = serie_size - 1\n",
    "Y_train_encoded = train['label']\n",
    "train.drop('label', axis=1, inplace=True)\n",
    "X_train_encoded = train[[last_month, 'encoded']]\n",
    "\n",
    "Y_valid_encoded = valid['label']\n",
    "valid.drop('label', axis=1, inplace=True)\n",
    "X_valid_encoded = valid[[last_month, 'encoded']]\n",
    "\n",
    "print(\"Train set\", X_train_encoded.shape)\n",
    "print(\"Validation set\", X_valid_encoded.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
